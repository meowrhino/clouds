- name: Ejecuta scraper Python
  run: |
    set -euo pipefail
    python - <<'PY'
    import json, requests
    from bs4 import BeautifulSoup, Comment

    def main():
        url = "https://meowrhino.neocities.org/"
        r = requests.get(
            url,
            timeout=30,
            headers={"User-Agent": "Mozilla/5.0 (GitHub Actions scraper)"}
        )
        r.raise_for_status()

        # Usar .content para que los acentos salgan bien
        soup = BeautifulSoup(r.content, "html.parser")
        cont = soup.find(id="proyectes")
        if cont is None:
            raise SystemExit("No se encontró #proyectes en la página")

        data = {}                 # {"main quests": [ {name,links}, ... ], ...}
        current_cat = None
        current_name = None
        current_links = []

        def flush():
            nonlocal current_name, current_links
            if current_name and current_links:
                cat = current_cat or "uncategorized"
                data.setdefault(cat, []).append({
                    "name": current_name,
                    "links": current_links
                })
            current_name = None
            current_links = []

        for el in cont.children:
            if isinstance(el, Comment):
                flush()
                current_cat = el.strip()
                if current_cat:
                    data.setdefault(current_cat, [])
                continue

            tag = getattr(el, "name", None)
            if tag == "ainfo":
                flush()
                current_name = el.get_text(strip=True)
                current_links = []
            elif tag == "a" and current_name:
                href = el.get("href")
                if href:
                    current_links.append(href)
            elif tag == "br":
                flush()
            else:
                # ignorar textos/espacios/otros tags
                pass

        flush()  # por si el último bloque no cerró con <br>

        with open("proyectos.json", "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

        print("Categorías:", ", ".join(f"{k}({len(v)})" for k, v in data.items()))

    if __name__ == "__main__":
        main()
    PY
