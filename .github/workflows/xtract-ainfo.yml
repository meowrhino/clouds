- name: Ejecuta scraper Python
  run: |
    python <<'PY'
    import requests, json
    from bs4 import BeautifulSoup, Comment

    url = "https://meowrhino.neocities.org/"
    r = requests.get(url, timeout=30)
    r.raise_for_status()

    # Usar .content + ensure_ascii=False para acentos OK
    soup = BeautifulSoup(r.content, "html.parser")

    cont = soup.find(id="proyectes")
    if cont is None:
        raise SystemExit("No se encontró #proyectes en la página")

    data = {}                 # dict: { "main quests": [ {name,links}, ... ], ... }
    current_cat = None
    current_name = None
    current_links = []

    def flush():
        nonlocal current_name, current_links
        if current_name and current_links:
            cat = current_cat or "uncategorized"
            data.setdefault(cat, []).append({
                "name": current_name,
                "links": current_links
            })
        current_name = None
        current_links = []

    for el in cont.children:
        # Comentarios HTML => nombre de categoría
        if isinstance(el, Comment):
            flush()
            current_cat = el.strip()
            if current_cat:
                data.setdefault(current_cat, [])
            continue

        tag = getattr(el, "name", None)
        if tag == "ainfo":
            flush()
            current_name = el.get_text(strip=True)
            current_links = []
        elif tag == "a" and current_name:
            href = el.get("href")
            if href:
                current_links.append(href)
        elif tag == "br":
            flush()
        else:
            # ignorar textos/espacios/otros tags
            pass

    # por si el último bloque no cerró con <br>
    flush()

    with open("proyectos.json", "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    PY
